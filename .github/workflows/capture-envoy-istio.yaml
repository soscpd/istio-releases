name: Capture Envoy & Istio Releases

# Ops notes (condensed):
# - Permissions: contents: write
# - Concurrency: capture-releases (no cancel-in-progress)
# - Tools: jq, curl, skopeo, yq (v4.x)
# - Secret: GITHUB_TOKEN (rate-limit safe)

on:
  push:
    branches: [envoy-istio-metadata]
  workflow_dispatch:
    inputs:
      branch:
        description: 'Target branch/ref (used by checkout)'
        required: true
        default: 'envoy-istio-metadata'
        type: string
      start_from:
        description: 'Global/per-repo baseline (e.g. v1.28.0 or owner/repo@vX.Y.Z,...)'
        required: false
        type: string

permissions:
  contents: write

concurrency:
  group: capture-releases
  cancel-in-progress: false

jobs:
  capture:
    runs-on: ubuntu-latest
    outputs:
      created: ${{ steps.finish.outputs.CREATED_JSON }}   # JSON array of created file paths
      failed:  ${{ steps.finish.outputs.FAILED_JSON }}    # JSON array of failures
    env:
      CONFIG_JSON: |
        {
          "targets": [
            {
              "repo": "envoyproxy/envoy",
              "output_dir": "releases/envoy/{tag}",
              "strip_v_prefix": true,
              "include_prereleases": false,
              "use_tags_if_no_releases": true,
              "ignore": { "tags": [], "regexes": [] },
              "images": [
                { "id": "base-image",            "ref": "envoyproxy/envoy:{tag}" },
                { "id": "base-image.distroless", "ref": "envoyproxy/envoy:distroless-{tag}" }
              ],
              "extra_refs": [
                { "key": "release",      "resolve_for": "{tag}" },
                { "key": "release-fips", "resolve_for": "{tag}" }
              ]
            },
            {
              "repo": "istio/istio",
              "output_dir": "releases/istio/{tag}",
              "strip_v_prefix": false,
              "include_prereleases": false,
              "use_tags_if_no_releases": true,
              "ignore": { "tags": [], "regexes": [] },
              "images": [
                { "id": "base-image",            "ref": "gcr.io/istio-release/pilot:{tag_no_v}" },
                { "id": "base-image.distroless", "ref": "gcr.io/istio-release/pilot:{tag_no_v}-distroless" }
              ],
              "extra_refs": [
                { "key": "release",      "resolve_for": "{tag}" },
                { "key": "release-fips", "resolve_for": "{tag}" }
              ]
            }
          ]
        }
      RUNTIME_IGNORE: ""   # e.g. "envoyproxy/envoy@v1.0.0,istio/istio@1.27.0"
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.branch }}
          fetch-depth: 0

      - name: Install deps
        shell: bash
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl skopeo
          sudo wget -qO /usr/local/bin/yq \
            https://github.com/mikefarah/yq/releases/download/v4.44.3/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq

      - name: Ensure state
        shell: bash
        run: |
          mkdir -p state
          test -f state/releases-processed.json || echo '{}' > state/releases-processed.json
          test -f state/capture-failed.json     || echo '[]' > state/capture-failed.json

      - name: Capture unseen releases (best-effort)
        id: cap
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          START_FROM: ${{ inputs.start_from }}
        run: |
          set -Eeuo pipefail
          CONFIG='${{ env.CONFIG_JSON }}'
          STATE=state/releases-processed.json
          CREATED_JSON='[]'
          FAILED_JSON='[]'

          jqp() { printf '%s' "$1" | jq -r "$2"; }

          declare -A START_MAP=(); START_GLOBAL=""
          if [[ -n "${START_FROM:-}" ]]; then
            IFS=',' read -ra _sf_items <<< "$START_FROM"
            for it in "${_sf_items[@]}"; do
              it="${it//[[:space:]]/}"; [[ -z "$it" ]] && continue
              if [[ "$it" == *@* ]]; then START_MAP["${it%@*}"]="${it#*@}"; else START_GLOBAL="$it"; fi
            done
          fi

          semver_ge(){ local A="${1#v}" B="${2#v}"; IFS='.' read -r a1 a2 a3 <<<"$A"; IFS='.' read -r b1 b2 b3 <<<"$B"; a1=${a1:-0};a2=${a2:-0};a3=${a3:-0};b1=${b1:-0};b2=${b2:-0};b3=${b3:-0}; ((a1>b1))&&return 0;((a1<b1))&&return 1; ((a2>b2))&&return 0;((a2<b2))&&return 1; ((a3>=b3))&&return 0||return 1; }
          meets_start_baseline(){ local repo="$1" tag="$2" base="${START_MAP[$repo]:-$START_GLOBAL}"; [[ -z "$base" ]] && return 0; semver_ge "$tag" "$base"; }

          safe_curl(){ if [[ -n "${GITHUB_TOKEN:-}" ]]; then curl -fsSL -H "Authorization: Bearer ${GITHUB_TOKEN}" -H "Accept: application/vnd.github+json" "$@"; else curl -fsSL -H "Accept: application/vnd.github+json" "$@"; fi; }

          declare -A IGNORE_RT=()
          if [[ -n "${RUNTIME_IGNORE:-}" ]]; then
            IFS=',' read -ra _items <<< "$RUNTIME_IGNORE"
            for it in "${_items[@]}"; do it="${it//[[:space:]]/}"; [[ -n "$it" ]] && IGNORE_RT["$it"]=1; done
          fi

          jq_get(){ printf '%s' "$1" | jq -r "$2 // empty"; }

          list_tags() {
            local owner="$1" repo="$2" include_pr="$3" use_fallback="$4"
            local all="[]"; local page=1
            while :; do
              local r; r=$(safe_curl "https://api.github.com/repos/$owner/$repo/releases?per_page=100&page=$page" || echo '[]')
              all=$( { printf '%s' "$all"; printf '%s' "$r"; } | jq -c -s 'add' )
              if [ "$(printf '%s' "$r" | jq 'length')" -lt 100 ]; then break; fi; ((page++))
            done
            local out="[]"
            if [ "$(printf '%s' "$all" | jq 'length')" -gt 0 ]; then
              if [[ "$include_pr" == "true" ]]; then out=$(printf '%s' "$all" | jq -c '[ .[] | select(.draft==false) ] | sort_by(.created_at) | map(.tag_name)'); else out=$(printf '%s' "$all" | jq -c '[ .[] | select(.draft==false and .prerelease==false) ] | sort_by(.created_at) | map(.tag_name)'); fi
            elif [[ "$use_fallback" == "true" ]]; then
              local tags="[]"; page=1
              while :; do
                local t; t=$(safe_curl "https://api.github.com/repos/$owner/$repo/tags?per_page=100&page=$page" || echo '[]')
                tags=$( { printf '%s' "$tags"; printf '%s' "$t"; } | jq -c -s 'add' )
                if [ "$(printf '%s' "$t" | jq 'length')" -lt 100 ]; then break; fi; ((page++))
              done
              out=$(printf '%s' "$tags" | jq -c 'reverse | map(.name)')
            fi
            echo "$out"
          }

          is_valid_tag(){ [[ "$1" =~ ^v?[0-9]+\.[0-9]+\.[0-9]+$ ]]; }

          resolve_ref(){
            local owner="$1" repo="$2" ref="$3"
            local r type sha
            r=$(safe_curl "https://api.github.com/repos/$owner/$repo/git/ref/tags/${ref}" 2>/dev/null || true)
            type=$(jq -r '.object.type // empty' <<<"$r")
            sha=$(jq -r '.object.sha  // empty' <<<"$r")
            if [[ -n "$type" ]]; then
              if [[ "$type" == "tag" ]]; then
                local t; t=$(safe_curl "https://api.github.com/repos/$owner/$repo/git/tags/${sha}" 2>/dev/null || true)
                echo "$(jq -r '.object.sha // empty' <<<"$t")"; return 0
              else echo "$sha"; return 0; fi
            fi
            r=$(safe_curl "https://api.github.com/repos/$owner/$repo/git/ref/heads/${ref}" 2>/dev/null || true)
            sha=$(jq -r '.object.sha // empty' <<<"$r"); [[ -n "$sha" ]] && { echo "$sha"; return 0; }
            echo ""
          }

          process_one(){
            local owner="$1" name="$2" tag="$3" target_json="$4"
            local strip_v; strip_v=$(jq_get "$target_json" '.strip_v_prefix'); [[ -z "$strip_v" ]] && strip_v="false"
            local tag_no_v="$tag"; if [[ "$strip_v" == "true" && "$tag_no_v" =~ ^v ]]; then tag_no_v="${tag_no_v#v}"; fi
            local extra='{}'; local sha_errors="[]"
            local ecnt; ecnt=$(jq '(.extra_refs // []) | length' <<<"$target_json")
            for (( i=0; i<ecnt; i++ )); do
              local key ref_tpl ref sha
              key=$(jq -r ".extra_refs[$i].key" <<<"$target_json")
              ref_tpl=$(jq -r ".extra_refs[$i].resolve_for" <<<"$target_json")
              ref="${ref_tpl//\{tag\}/$tag}"
              sha=$(resolve_ref "$owner" "$name" "$ref" || true)
              if [[ -n "$sha" ]]; then extra=$(jq -c --arg k "$key" --arg s "$sha" '. + {($k): $s}' <<<"$extra")
              else sha_errors=$(jq -c --arg k "$key" --arg r "$ref" '. + [ {ref_key:$k, ref:$r} ]' <<<"$sha_errors"); fi
            done
            local dig='{}'; local dig_err='[]'
            local icnt; icnt=$(jq '(.images // []) | length' <<<"$target_json")
            for (( j=0; j<icnt; j++ )); do
              local id tpl ref digv
              id=$(jq -r ".images[$j].id" <<<"$target_json")
              tpl=$(jq -r ".images[$j].ref" <<<"$target_json")
              ref="${tpl//\{tag\}/$tag}"; ref="${ref//\{tag_no_v\}/$tag_no_v}"
              if digv=$(skopeo inspect --tls-verify=true --format '{{.Digest}}' "docker://$ref" 2>/tmp/err.$$); then
                dig=$(jq -c --arg id "$id" --arg ref "$ref" --arg d "$digv" '. + {($id): {ref:$ref, digest:$d}}' <<<"$dig")
              else
                dig_err=$(jq -c --arg id "$id" --arg ref "$ref" --arg msg "$(tail -1 /tmp/err.$$)" '. + [ {id:$id, ref:$ref, error:$msg} ]' <<<"$dig_err")
              fi
              rm -f /tmp/err.$$
            done
            local out_dir_tpl out_dir out_file
            out_dir_tpl=$(jq_get "$target_json" '.output_dir')
            out_dir="${out_dir_tpl//\{tag\}/$tag}"
            mkdir -p "$out_dir"
            out_file="$out_dir/release.yaml"
            local base_ref base_dig dist_ref dist_dig rel_sha fips_sha
            base_ref=$(printf '%s' "$dig"   | jq -r '."base-image".ref // empty')
            base_dig=$(printf '%s' "$dig"   | jq -r '."base-image".digest // empty')
            dist_ref=$(printf '%s' "$dig"   | jq -r '."base-image.distroless".ref // empty')
            dist_dig=$(printf '%s' "$dig"   | jq -r '."base-image.distroless".digest // empty')
            rel_sha=$(printf '%s' "$extra"  | jq -r '."release" // empty')
            fips_sha=$(printf '%s' "$extra" | jq -r '."release-fips" // empty')
            jq -n --arg base_reg "$base_ref" --arg base_dig "$base_dig" --arg dist_reg "$dist_ref" --arg dist_dig "$dist_dig" --arg owner "$owner" --arg name "$name" --arg rel_sha "$rel_sha" --arg fips_sha "$fips_sha" '
              def nn(s): if s == "" then null else s end;
              def refify(s): if s == "" then null else ($owner + "/" + $name + "@" + s) end;
              { "base-image": { "registry": nn($base_reg), "version": nn($base_dig),
                  "distroless": { "registry": nn($dist_reg), "version": nn($dist_dig) } },
                "release": { "ref": refify($rel_sha) },
                "release-fips": { "ref": refify($fips_sha) } }' | yq -P > "$out_file"
            echo "$out_file"
            echo "$sha_errors" > state/.sha_errors.json
            echo "$dig_err"    > state/.dig_errors.json
          }

          CREATED='[]'; FAILED='[]'
          while IFS= read -r t; do
            repo=$(jq_get "$t" '.repo'); owner="${repo%%/*}"; name="${repo##*/}"
            include=$(jq_get "$t" '.include_prereleases'); [[ -z "$include" ]] && include="false"
            fallback=$(jq_get "$t" '.use_tags_if_no_releases'); [[ -z "$fallback" ]] && fallback="true"
            tags_json=$(list_tags "$owner" "$name" "$include" "$fallback")
            seen=$(jq -c --arg k "$repo" '.[$k].processed // []' "$STATE")
            while IFS= read -r tag; do
              if ! is_valid_tag "$tag"; then echo "== skip (non-semver) $repo $tag"; continue; fi
              if ! meets_start_baseline "$repo" "$tag"; then echo "== skip (before baseline ${START_MAP[$repo]:-$START_GLOBAL}) $repo $tag"; continue; fi
              if [[ -n "${IGNORE_RT["$repo@$tag"]+x}" ]]; then echo "== skip (runtime ignore) $repo $tag"; continue; fi
              if printf '%s' "$seen" | jq -e --arg tg "$tag" 'index($tg) != null' >/dev/null; then continue; fi
              echo "== process $repo $tag"
              if file_path=$(process_one "$owner" "$name" "$tag" "$t"); then
                CREATED=$(printf '%s' "$CREATED" | jq -c --arg f "$file_path" '. + [ $f ]')
                new_seen=$(printf '%s' "$seen" | jq -c --arg tg "$tag" '. + [ $tg ] | unique')
                jq --arg k "$repo" --argjson arr "$new_seen" '.[$k].processed = $arr' "$STATE" > state/.tmp && mv state/.tmp "$STATE"
              else
                FAILED=$(printf '%s' "$FAILED" | jq -c --arg r "$repo" --arg tg "$tag" '. + [ {repo:$r, tag:$tg, error:"capture-failed"} ]')
              fi
              if [[ -s state/.sha_errors.json || -s state/.dig_errors.json ]]; then
                sha_e=$(cat state/.sha_errors.json 2>/dev/null || echo '[]')
                dig_e=$(cat state/.dig_errors.json 2>/dev/null || echo '[]')
                jq -n --arg r "$repo" --arg tg "$tag" --argjson se "$sha_e" --argjson de "$dig_e" \
                  '{repo:$r, tag:$tg, sha_errors:$se, digest_errors:$de, when:(now|todate)}' \
                | jq -s '.[0]' > state/.last_fail.json
                jq -s '.[0] + [.[1]]' state/capture-failed.json state/.last_fail.json > state/.tmp && mv state/.tmp state/capture-failed.json
                rm -f state/.sha_errors.json state/.dig_errors.json state/.last_fail.json || true
              fi
            done < <(jq -r '.[]' <<<"$tags_json")
          done < <(jq -c '.targets[]' <<<"$CONFIG")

          {
            echo "CREATED<<EOF"; echo "$CREATED"; echo "EOF";
            echo "FAILED<<EOF";  echo "$FAILED";  echo "EOF";
          } >> "$GITHUB_OUTPUT"

      - name: Commit outputs (if any)
        if: ${{ (steps.cap.outputs.CREATED != '[]' || steps.cap.outputs.FAILED != '[]') && env.ACT != 'true' }}
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: capture Envoy/Istio releases (best-effort)"
          file_pattern: |
            releases/**
            state/releases-processed.json
            state/capture-failed.json

      - name: Finish / expose outputs
        id: finish
        shell: bash
        run: |
          echo 'CREATED_JSON=${{ steps.cap.outputs.CREATED }}' >> "$GITHUB_OUTPUT"
          echo 'FAILED_JSON=${{ steps.cap.outputs.FAILED }}'   >> "$GITHUB_OUTPUT"

  # NEW: Chunk the created file list to respect the 256 matrix cap
  prepare_fanout:
    needs: capture
    if: ${{ needs.capture.outputs.created != '[]' }}
    runs-on: ubuntu-latest
    outputs:
      chunks: ${{ steps.chunk.outputs.CHUNKS }}   # JSON array of arrays
    env:
      MAX_PER_JOB: "64"                           # tune batch size if desired
    steps:
      - id: chunk
        shell: bash
        run: |
          set -euo pipefail
          files='${{ needs.capture.outputs.created }}'
          size=${MAX_PER_JOB}
          chunks=$(printf '%s' "$files" | jq -c --argjson s "$size" '
            def chunks(n): [ range(0; length; n) as $i | .[$i : ($i+n)] ];
            ( . as $a | if ($a|type)=="array" and ($a|length)>0 then chunks($s) else [] end )
          ')
          echo "CHUNKS<<EOF" >> "$GITHUB_OUTPUT"
          echo "$chunks"     >> "$GITHUB_OUTPUT"
          echo "EOF"         >> "$GITHUB_OUTPUT"

  act_on_captured:
    needs: prepare_fanout
    if: ${{ needs.prepare_fanout.outputs.chunks != '[]' }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        chunk: ${{ fromJSON(needs.prepare_fanout.outputs.chunks) }}
    steps:
      - uses: actions/checkout@v4
      - name: Process chunk
        shell: bash
        run: |
          echo '${{ matrix.chunk }}' | jq -r '.[]' | while read -r f; do
            echo "Processing ${f}"
            test -f "${f}" && cat "${f}" || echo "(file missing?)"
            # TODO: build image / notify / open PR, whatever
          done
